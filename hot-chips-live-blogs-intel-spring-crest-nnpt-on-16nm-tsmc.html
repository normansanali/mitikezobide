<!doctype html><html class=no-js lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Intel Spring Crest NNP-T on 16nm TSMC - FluxDash</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content="08:23PM EDT - Intel is showing us some of the design features of its new ML training product, Spring Crest. 08:23PM EDT - NNP-T = Training 08:24PM EDT - Spring Crest is what Intel purchased when it acquired Nervana in 2016. THis is the big chip that came with the acquisition"><meta name=robots content="index,follow,noarchive"><meta property="og:title" content="Intel Spring Crest NNP-T on 16nm TSMC"><meta property="og:description" content="08:23PM EDT - Intel is showing us some of the design features of its new ML training product, Spring Crest. 08:23PM EDT - NNP-T = Training 08:24PM EDT - Spring Crest is what Intel purchased when it acquired Nervana in 2016. THis is the big chip that came with the acquisition"><meta property="og:type" content="article"><meta property="og:url" content="/hot-chips-live-blogs-intel-spring-crest-nnpt-on-16nm-tsmc.html"><meta property="article:section" content="post"><meta property="article:published_time" content="2024-07-21T00:00:00+00:00"><meta property="article:modified_time" content="2024-07-21T00:00:00+00:00"><meta itemprop=name content="Intel Spring Crest NNP-T on 16nm TSMC"><meta itemprop=description content="08:23PM EDT - Intel is showing us some of the design features of its new ML training product, Spring Crest. 08:23PM EDT - NNP-T = Training 08:24PM EDT - Spring Crest is what Intel purchased when it acquired Nervana in 2016. THis is the big chip that came with the acquisition"><meta itemprop=datePublished content="2024-07-21T00:00:00+00:00"><meta itemprop=dateModified content="2024-07-21T00:00:00+00:00"><meta itemprop=wordCount content="721"><meta itemprop=keywords content><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=https://assets.cdnweb.info/hugo/mainroad/css/style.css><link rel="shortcut icon" href=./favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=./index.html title=FluxDash rel=home><div class="logo__item logo__text"><div class=logo__title>FluxDash</div></div></a></div><div class=divider></div></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>Intel Spring Crest NNP-T on 16nm TSMC</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2024-07-21T00:00:00Z>July 21, 2024</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=./categories/blog/ rel=category>blog</a></span></div></div></header><div class="content post__content clearfix"><p><a id=post0819202309 href=#><span class=lb_time>08:23PM EDT</span></a> - Intel is showing us some of the design features of its new ML training product, Spring Crest.</p><p><a id=post0819202353 href=#><span class=lb_time>08:23PM EDT</span></a> - NNP-T = Training</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14757/IMG_20190819_172340_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819202418 href=#><span class=lb_time>08:24PM EDT</span></a> - Spring Crest is what Intel purchased when it acquired Nervana in 2016. THis is the big chip that came with the acquisition</p><p><a id=post0819202443 href=#><span class=lb_time>08:24PM EDT</span></a> - Trend in Neural Networks means compute requirements doubles every 3.5x months</p><p><a id=post0819202529 href=#><span class=lb_time>08:25PM EDT</span></a> - Need to fill the die with as much compute that can be fed</p><p><a id=post0819202545 href=#><span class=lb_time>08:25PM EDT</span></a> - DL is as much as a communication problem as it is a compute problem</p><p><a id=post0819202553 href=#><span class=lb_time>08:25PM EDT</span></a> - Need a scale-out model for larger models</p><p><a id=post0819202628 href=#><span class=lb_time>08:26PM EDT</span></a> - Want to train a model as fast as possible within a power budget. Aim for high utilization, and a scalable solution</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14757/IMG_20190819_172558_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819202643 href=#><span class=lb_time>08:26PM EDT</span></a> - Balance between compute, comms, and memory</p><p><a id=post0819202655 href=#><span class=lb_time>08:26PM EDT</span></a> - Best is to be compute bound on all but the smallest problems</p><p><a id=post0819202705 href=#><span class=lb_time>08:27PM EDT</span></a> - Keep data local and reuse it as much as possible</p><p><a id=post0819202714 href=#><span class=lb_time>08:27PM EDT</span></a> - Consistent programming model</p><p><a id=post0819202730 href=#><span class=lb_time>08:27PM EDT</span></a> - Flexibility for future workloads</p><p><a id=post0819202751 href=#><span class=lb_time>08:27PM EDT</span></a> - Spring Crest uses 2.5D</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14757/IMG_20190819_172739_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819202757 href=#><span class=lb_time>08:27PM EDT</span></a> - PCIe Gen 4 x16 with host CPU</p><p><a id=post0819202803 href=#><span class=lb_time>08:28PM EDT</span></a> - 4x 8GB HBM2</p><p><a id=post0819202815 href=#><span class=lb_time>08:28PM EDT</span></a> - 24 Tensor Processors (TPCs), Up to 119 TOPs</p><p><a id=post0819202825 href=#><span class=lb_time>08:28PM EDT</span></a> - 8x8 lanes SerDes for chip-to-chip communications</p><p><a id=post0819202848 href=#><span class=lb_time>08:28PM EDT</span></a> - Built on 16FF+ TSMC with CoWoS</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14757/IMG_20190819_172830_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819202904 href=#><span class=lb_time>08:29PM EDT</span></a> - 680mm2 with 1200mm2 passive interposer, 27 billion transistors</p><p><a id=post0819202909 href=#><span class=lb_time>08:29PM EDT</span></a> - Up to 1.1 GHz Core frequ</p><p><a id=post0819202913 href=#><span class=lb_time>08:29PM EDT</span></a> - HBM2-2400</p><p><a id=post0819202923 href=#><span class=lb_time>08:29PM EDT</span></a> - Supports PCIe and OAM (Open Compute)</p><p><a id=post0819202939 href=#><span class=lb_time>08:29PM EDT</span></a> - TensorFlow and PaddlePaddle first frameworks supported, more to come. Uses NGraph</p><p><a id=post0819203007 href=#><span class=lb_time>08:30PM EDT</span></a> - Intel provide the low level compiler performance optimizations</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14757/IMG_20190819_172943_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819203025 href=#><span class=lb_time>08:30PM EDT</span></a> - Tensor based ISA</p><p><a id=post0819203030 href=#><span class=lb_time>08:30PM EDT</span></a> - Limited instruction set</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14757/IMG_20190819_173015_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819203041 href=#><span class=lb_time>08:30PM EDT</span></a> - Extensible with custom microcontroller custom instructions</p><p><a id=post0819203053 href=#><span class=lb_time>08:30PM EDT</span></a> - Same distributed model on-chip and off-chip</p><p><a id=post0819203058 href=#><span class=lb_time>08:30PM EDT</span></a> - Compute has affinity for local data</p><p><a id=post0819203108 href=#><span class=lb_time>08:31PM EDT</span></a> - DL worklaods are dominated by a limited set of operations</p><p><a id=post0819203116 href=#><span class=lb_time>08:31PM EDT</span></a> - Explicit SW memory management and message passing</p><p><a id=post0819203155 href=#><span class=lb_time>08:31PM EDT</span></a> - 150-250W power</p><p><a id=post0819203225 href=#><span class=lb_time>08:32PM EDT</span></a> - Here's a TPC</p><p><a id=post0819203236 href=#><span class=lb_time>08:32PM EDT</span></a> - On-chip router, controller, two arrays, memory</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14757/IMG_20190819_173216_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819203314 href=#><span class=lb_time>08:33PM EDT</span></a> - Each 32x32 array has pre-op and post-op support</p><p><a id=post0819203323 href=#><span class=lb_time>08:33PM EDT</span></a> - dedicated convolution engine for non-MAC compute</p><p><a id=post0819203352 href=#><span class=lb_time>08:33PM EDT</span></a> - BFloat16 support with FP32 accumulation</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14757/IMG_20190819_173337_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819203444 href=#><span class=lb_time>08:34PM EDT</span></a> - BF16 32x32 MAC Core</p><p><a id=post0819203457 href=#><span class=lb_time>08:34PM EDT</span></a> - 2x Multiply Cores per TPC to amortize SoC resources</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14757/IMG_20190819_173428_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819203517 href=#><span class=lb_time>08:35PM EDT</span></a> - Compound vector pipeline with DL specific optimizations on non-GEMM ops</p><p><a id=post0819203559 href=#><span class=lb_time>08:35PM EDT</span></a> - 1.22 TBps raw HBM2 bandwidth</p><p><a id=post0819203608 href=#><span class=lb_time>08:36PM EDT</span></a> - 2.5MB / TPC local scratchpad memory</p><p><a id=post0819203617 href=#><span class=lb_time>08:36PM EDT</span></a> - Native Tensor Transpose without any overhead</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14757/IMG_20190819_173539_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819203627 href=#><span class=lb_time>08:36PM EDT</span></a> - 1.4 TBps local read/write bw per TPC</p><p><a id=post0819203639 href=#><span class=lb_time>08:36PM EDT</span></a> - Cna do TPC-to-TPC data movement without HBM involvement</p><p><a id=post0819203709 href=#><span class=lb_time>08:37PM EDT</span></a> - 2D Meshes, multiple meshes for different data types</p><p><a id=post0819203719 href=#><span class=lb_time>08:37PM EDT</span></a> - prioritized for throughput over latency</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14757/IMG_20190819_173651_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819203736 href=#><span class=lb_time>08:37PM EDT</span></a> - 1.3 TBps bandwidth in each direction</p><p><a id=post0819203810 href=#><span class=lb_time>08:38PM EDT</span></a> - Designed for a fully connected topology</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14757/IMG_20190819_173751_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819203821 href=#><span class=lb_time>08:38PM EDT</span></a> - Looks like one large system to simplify the software model</p><p><a id=post0819203831 href=#><span class=lb_time>08:38PM EDT</span></a> - Up to 1024 nodes supported gluelessly</p><p><a id=post0819203847 href=#><span class=lb_time>08:38PM EDT</span></a> - 3.58 TBps total bidirectional SerDes BW per chip</p><p><a id=post0819203903 href=#><span class=lb_time>08:39PM EDT</span></a> - Fully programable router with multi-cast support and virtual channel support</p><p><a id=post0819203959 href=#><span class=lb_time>08:39PM EDT</span></a> - Aiming for high utilization across many GEMM sizes</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14757/IMG_20190819_173939_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819204017 href=#><span class=lb_time>08:40PM EDT</span></a> - Most architectures do well on large square GEMMs. Not all hardware can do different matrix sizes well</p><p><a id=post0819204047 href=#><span class=lb_time>08:40PM EDT</span></a> - Looking at GEMM utilization that is difficult to solve</p><p><a id=post0819204201 href=#><span class=lb_time>08:42PM EDT</span></a> - Ring topology bandwidth benchmarked across 32-chips</p><p><a id=post0819204219 href=#><span class=lb_time>08:42PM EDT</span></a> - Equivalent bandwidth between cards and between racks</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14757/IMG_20190819_174139_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819204327 href=#><span class=lb_time>08:43PM EDT</span></a> - Performance measured using 22 TPCs at 900 MHz core clock and 2 GHz HBM. Host is Xeon Gold 6130T @ 2.1 GHz</p><p><a id=post0819204354 href=#><span class=lb_time>08:43PM EDT</span></a> - Whisper connectivity</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14757/IMG_20190819_174434_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819204518 href=#><span class=lb_time>08:45PM EDT</span></a> - Latency card-to-card at 3-9 microseconds, cross chassis at 30-36 microseconds</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14757/IMG_20190819_174541_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819204601 href=#><span class=lb_time>08:46PM EDT</span></a> - Coming to customers soon</p><p><a id=post0819204604 href=#><span class=lb_time>08:46PM EDT</span></a> - Q&A</p><p><a id=post0819204704 href=#><span class=lb_time>08:47PM EDT</span></a> - Q: How do you support structured sparsity? A: More benchmarks to come</p><p><a id=post0819204731 href=#><span class=lb_time>08:47PM EDT</span></a> - Q: MLperf? A: Can't comment. More data before the end of the year</p><p><a id=post0819204929 href=#><span class=lb_time>08:49PM EDT</span></a> - That's a wrap. Next up Cerebras</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH51g5RwZqGnpGKwqbXPrGSloaaaeqO4zqCqZqGeqbKtedKpqaKml2Kws7HSrWSnpqCperC6jGptp6VdqcCurw%3D%3D</p></div></article></main><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=./mario-dumaual-death-news-reporter-dead-or-alive.html rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>Is The ABS-CBN Reporter Dead Or Alive?</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=./i-dew-care-matcha-mood-green-tea-mask.html rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>I Dew Care Matcha Mood Mask May Soothe Angry Skin Fast</p></a></div></nav></div><aside class=sidebar><div class="widget-recent widget"><h4 class=widget__title>Recent Posts</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=./burger-king-officially-debuts-meatless-impossible-whopper.html>Burger King Officially Debuts Meatless Impossible Whopper</a></li><li class=widget__item><a class=widget__link href=./john-travolta-and-kelly-preston-spotted-at-countryside-mall.html>John Travolta and Kelly Preston spotted at Countryside Mall</a></li><li class=widget__item><a class=widget__link href=./josh-allen-reveals-if-buffalo-bills-have-taylor-swift-audible-call.html>Josh Allen Reveals If Buffalo Bills Have Taylor Swift Audible Call</a></li><li class=widget__item><a class=widget__link href=./kenneth-david-pilon-charged-with-hate-crimes-against-blm.html>Kenneth David Pilon Charged with Hate Crimes Against BLM</a></li><li class=widget__item><a class=widget__link href=./rilyn-dinyae.html>Rilyn Dinyae - Bio, Age, Net Worth, Single, Nationality, Facts</a></li></ul></div></div><div class="widget-categories widget"><h4 class=widget__title>Categories</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=./categories/blog/>blog</a></li></ul></div></div></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2024 FluxDash.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=https://assets.cdnweb.info/hugo/mainroad/js/menu.js></script>
<script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>